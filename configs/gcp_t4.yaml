# Google Cloud T4 GPU Configuration
# Balanced for T4 GPU (16GB VRAM)

stt:
  provider: "whisper"
  model: "medium"  # T4: Use medium model
  language: "en"
  device: "cuda"
  compute_type: "float16"
  batch_size: 16
  beam_size: 5
  vad_enabled: true
  vad_device: "cuda"
  vad_threshold: 0.5
  enable_flash_attention: false  # T4 doesn't support Flash Attention

llm:
  provider: "groq"
  model: "llama-3.1-8b-instant"
  temperature: 0.7
  max_tokens: 150
  stream: true

tts:
  provider: "kokoro"
  device: "cuda"
  voice: "af_sarah"
  speed: 1.0
  quality: "high"
  fallback_provider: "edge"

transport:
  type: "websocket"
  host: "0.0.0.0"
  port: 8000
  sample_rate: 16000
  channels: 1

gpu:
  enabled: true
  device_id: 0
  memory_fraction: 0.75  # T4: Conservative memory usage
  allow_growth: true
  mixed_precision: true
  optimize_for_latency: true
