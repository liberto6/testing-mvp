# RunPod GPU-Optimized Configuration
# Tuned for RunPod RTX 4090 / A100 instances

stt:
  provider: "whisper"
  model: "large-v3"
  language: "en"
  device: "cuda"
  compute_type: "float16"
  batch_size: 32
  beam_size: 5
  vad_enabled: true
  vad_device: "cuda"
  vad_threshold: 0.5
  enable_flash_attention: true

llm:
  provider: "groq"
  model: "llama-3.1-8b-instant"
  temperature: 0.7
  max_tokens: 150
  stream: true

tts:
  provider: "kokoro"
  device: "cuda"
  voice: "af_sarah"
  speed: 1.0
  quality: "high"
  fallback_provider: "edge"

transport:
  type: "websocket"
  host: "0.0.0.0"
  port: 8000
  sample_rate: 16000
  channels: 1

gpu:
  enabled: true
  device_id: 0
  memory_fraction: 0.85  # RunPod: Use more VRAM
  allow_growth: true
  mixed_precision: true
  optimize_for_latency: true
