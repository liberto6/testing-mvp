<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <title>English Academy AI - Streaming Pipeline</title>
    
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.19.0/dist/ort.all.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.19/dist/bundle.min.js"></script>

    <style>
        body { font-family: sans-serif; background: #121212; color: white; display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; margin: 0; }
        .card { background: #1e1e1e; padding: 40px; border-radius: 24px; text-align: center; width: 350px; border: 1px solid #333; }
        .indicator { width: 70px; height: 70px; border-radius: 50%; background: #333; margin: 20px auto; transition: 0.3s; border: 4px solid #121212; }
        .listening { background: #ff4b4b !important; box-shadow: 0 0 20px #ff4b4b; }
        .processing { background: #4b96ff !important; box-shadow: 0 0 20px #4b96ff; animation: pulse 1s infinite; }
        .speaking { background: #00e676 !important; box-shadow: 0 0 20px #00e676; animation: pulse 1s infinite; }
        @keyframes pulse { 0% { transform: scale(1); } 50% { transform: scale(1.05); } 100% { transform: scale(1); } }
        button { padding: 15px 30px; border-radius: 50px; border: none; background: #00c853; color: white; font-weight: bold; cursor: pointer; width: 100%; }
        button:disabled { background: #444; cursor: not-allowed; }
        #status { margin-top: 20px; color: #aaa; font-size: 0.9rem; }
    </style>
</head>
<body>

<div class="card">
    <h1>Sarah AI</h1>
    <div id="indicator" class="indicator"></div>
    <p id="status">Cargando inteligencia...</p>
    <button id="startBtn" disabled>ESPERANDO SISTEMA...</button>
</div>

<script>
    const startBtn = document.getElementById('startBtn');
    const statusText = document.getElementById('status');
    const indicator = document.getElementById('indicator');

    // 1. Verificar carga de librer√≠as
    const checkLibs = setInterval(() => {
        if (typeof ort !== 'undefined' && typeof vad !== 'undefined') {
            clearInterval(checkLibs);
            startBtn.disabled = false;
            startBtn.innerText = "EMPEZAR CLASE";
            statusText.innerText = "Listo para conectar.";
        }
    }, 500);

    // 2. Conexi√≥n WebSocket
    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
    const ws = new WebSocket(`${protocol}//${window.location.host}/ws`);

    ws.onopen = () => { statusText.innerText = "Conectado. Pulsa el bot√≥n."; };
    ws.onclose = () => { statusText.innerText = "Desconectado."; };

        // --- COLA DE AUDIO (Audio Queue) ---
    const audioQueue = [];
    let isPlaying = false;
    let isAiSpeaking = false; 
    let currentAudio = null;
    let lastAiSpeechTime = 0; // Timestamp de cu√°ndo termin√≥ de hablar la IA

    function stopAudio() {
        // Funci√≥n para interrumpir la reproducci√≥n (Barge-in)
        isPlaying = false;
        isAiSpeaking = false;
        audioQueue.length = 0; // Vaciar cola
        lastAiSpeechTime = Date.now(); // Marcar interrupci√≥n como fin de habla
        
        if (currentAudio) {
            currentAudio.pause();
            currentAudio.currentTime = 0;
            currentAudio = null;
        }
        
        statusText.innerText = "Interrumpido.";
        indicator.className = "indicator";
    }

    ws.onmessage = (event) => {
        // Recibimos un chunk de audio (una frase)
        const blob = new Blob([event.data], { type: 'audio/wav' });
        const url = URL.createObjectURL(blob);
        
        audioQueue.push(url);
        
        if (!isPlaying) {
            statusText.innerText = "Sarah est√° hablando...";
            indicator.className = "indicator speaking";
            processQueue();
        }
    };

    async function processQueue() {
        if (audioQueue.length === 0) {
            isPlaying = false;
            // Peque√±o delay para evitar condiciones de carrera
            setTimeout(() => {
                if (audioQueue.length === 0 && !isPlaying) {
                    isAiSpeaking = false;
                    lastAiSpeechTime = Date.now(); // Registramos cu√°ndo par√≥
                    statusText.innerText = "Sarah te escucha.";
                    indicator.className = "indicator";
                }
            }, 100);
            return;
        }
        
        // Marcamos que la IA est√° hablando
        if (!isAiSpeaking) {
            isAiSpeaking = true;
        }

        isPlaying = true;
        const url = audioQueue.shift();
        currentAudio = new Audio(url);
        
        currentAudio.onended = () => {
            URL.revokeObjectURL(url); // Liberar memoria
            currentAudio = null;
            processQueue(); // Reproducir siguiente
        };
        
        try {
            await currentAudio.play();
        } catch (e) {
            console.error("Error reproduciendo audio:", e);
            processQueue(); // Intentar siguiente si falla
        }
    }

    // 3. L√≥gica VAD y Web Speech API (H√≠brido)
    startBtn.onclick = async () => {
    try {
        statusText.innerText = "Configurando...";
        
        // --- FASE 3: WEB SPEECH API CHECK ---
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const useWebSpeech = !!SpeechRecognition;
        
        if (useWebSpeech) {
            console.log("üöÄ Usando Web Speech API (Modo R√°pido)");
            const recognition = new SpeechRecognition();
            recognition.continuous = false; // Queremos frases cortas
            recognition.lang = 'en-US'; // O 'es-ES' y que el backend traduzca, pero 'en-US' fuerza pr√°ctica
            recognition.interimResults = false;
            recognition.maxAlternatives = 1;

            recognition.onstart = () => {
                indicator.className = "indicator listening";
                statusText.innerText = "Escuchando (Nativo)...";
            };

            recognition.onend = () => {
                // Reiniciar escucha siempre (Continuous listening)
                // Permitimos reinicio incluso si la IA habla, para permitir Barge-in
                try { recognition.start(); } catch(e) {}
            };

            recognition.onresult = (event) => {
                const text = event.results[0][0].transcript;
                console.log("üó£Ô∏è Detectado:", text);
                
                // --- AEC L√ìGICO ---
                // Si la IA est√° hablando o acaba de terminar hace muy poco (<500ms), 
                // y el texto detectado es sospechosamente corto o repetitivo, lo ignoramos.
                // PERO, si es Web Speech API nativa, el navegador suele tener buen AEC.
                // El problema real es cuando el volumen es muy alto y el AEC falla.
                // Intentaremos detectar interrupci√≥n real vs eco.
                
                // Si la IA habla, asumimos que es una interrupci√≥n (Barge-in)
                if (isAiSpeaking) {
                    console.log("‚ö° Posible interrupci√≥n detectada (IA hablando)...");
                    stopAudio(); // Paramos IA
                } else {
                     // Si la IA NO habla, pero acaba de terminar hace nada (Eco tard√≠o)
                     const timeSinceAiStop = Date.now() - lastAiSpeechTime;
                     if (timeSinceAiStop < 800) {
                         console.warn(`üõë Eco detectado (${timeSinceAiStop}ms tras IA). Ignorando: ${text}`);
                         return; 
                     }
                }
                
                indicator.className = "indicator processing";
                statusText.innerText = "Procesando...";
                
                if (ws.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify({text: text})); 
                }
            };
            
            // Fix para envio de JSON
            // La implementaci√≥n anterior enviaba ws.send(text).
            // FastAPI receive() -> {'type': 'websocket.receive', 'text': 'hola'}
            // Mi backend busca 'text' en el dict. ESTA BIEN.
            
            window.toggleRecognition = (enable) => {
                if (enable) {
                    try { recognition.start(); } catch(e) {}
                } else {
                    try { recognition.stop(); } catch(e) {}
                }
            };

            recognition.start();
            startBtn.style.display = 'none';
            statusText.innerText = "Sarah lista (Modo R√°pido).";

        } else {
            // --- FALLBACK: VAD + AUDIO RAW (Modo Lento) ---
            console.log("üê¢ Web Speech no soportado. Usando VAD + Audio Raw.");
            
            ort.env.wasm.numThreads = 1; 
            ort.env.wasm.proxy = false;
            ort.env.wasm.wasmPaths = "static/"; // Apuntar a local

            const stream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true
                } 
            });

            const myvad = await vad.MicVAD.new({
                stream: stream,
                modelURL: "static/silero_vad.onnx", // Local
                
                positiveSpeechThreshold: 0.6,
                negativeSpeechThreshold: 0.4,
                minSpeechDurationFrames: 4,
                preSpeechPadFrames: 1,
                redemptionFrames: 15,
                
                onSpeechStart: () => {
                    console.log("VAD: Speech Start");
                    
                    // --- AEC L√ìGICO PARA VAD ---
                    // En modo VAD es m√°s cr√≠tico porque no hay AEC nativo de Speech API.
                    
                    if (isAiSpeaking) {
                        // Si la IA habla, puede ser eco o interrupci√≥n.
                        // VAD de Silero es robusto, pero el audio raw incluye lo que sale del speaker si no hay AEC hardware.
                        // Como pedimos echoCancellation: true en getUserMedia, confiamos en ello.
                        // Pero si sigue fallando, es que el volumen es muy alto.
                        
                        // ESTRATEGIA: Asumir interrupci√≥n, PERO si es muy breve podr√≠a ser un pico de eco.
                        console.log("‚ö° VAD: Posible interrupci√≥n...");
                        stopAudio();
                    } else {
                         const timeSinceAiStop = Date.now() - lastAiSpeechTime;
                         if (timeSinceAiStop < 800) {
                             console.warn(`üõë VAD: Eco detectado (${timeSinceAiStop}ms tras IA). Ignorando.`);
                             // Forzamos "no speech" o simplemente no hacemos nada
                             return; 
                         }
                    }
                    
                    indicator.className = "indicator listening";
                    statusText.innerText = "Escuchando...";
                },
                
                onSpeechEnd: (audio) => {
                    // Doble check de eco al finalizar
                    const timeSinceAiStop = Date.now() - lastAiSpeechTime;
                    // Si la IA estaba hablando hace menos de 800ms cuando EMPEZ√ì este speech (aproximado), descartar.
                    // (Simplificado: si acabamos de parar la IA hace nada, es probable eco)
                    if (timeSinceAiStop < 800 && !isAiSpeaking) {
                         console.warn("üõë VAD: Descartando segmento por eco tard√≠o.");
                         return;
                    }

                    indicator.className = "indicator processing";
                    statusText.innerText = "Procesando...";
                    
                    const int16 = Int16Array.from(audio.map(n => n * 32767));
                    if (ws.readyState === WebSocket.OPEN) {
                        ws.send(int16.buffer); // ENVIAR BYTES
                    }
                }
            });

            myvad.start();
            startBtn.style.display = 'none';
            statusText.innerText = "Sarah lista (Modo VAD).";
            
            window.toggleRecognition = (enable) => {
                if (enable) myvad.start();
                else myvad.pause();
            };
        }

    } catch (err) {
        console.error("DETALLE DEL ERROR:", err);
        statusText.innerText = "Error de inicializaci√≥n.";
    }
    };
</script>

</body>
</html>
